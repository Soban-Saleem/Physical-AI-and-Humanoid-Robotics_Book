# Appendix C: Glossary

This appendix provides definitions for technical terms used throughout the Physical AI & Humanoid Robotics textbook. Terms are organized alphabetically for easy reference.

## A

**Action (in robotics)**: A long-running task with feedback and cancellation capabilities, typically used for navigation or manipulation tasks that take significant time to complete.

**Action Space**: The set of all possible actions that a robot can perform in its environment.

**Actor-Critic**: A reinforcement learning method that uses two neural networks - an actor that selects actions and a critic that evaluates those actions.

**ADRC (Architectural Decision Record)**: A document that captures an important architectural decision made along with its context and consequences.

**Affordance**: A property of an object that defines how it can be used or interacted with by an agent.

**AI Agent**: An autonomous entity that perceives its environment and takes actions to achieve goals.

**Apriltag**: A visual fiducial marker system that can be used for precise object detection and localization.

**Autonomous System**: A system that can operate independently without human intervention, making decisions based on its perceptions and goals.

## B

**Bipedal Locomotion**: The act of walking on two legs, which is more complex than wheeled locomotion due to balance requirements.

**Better-Auth**: A comprehensive authentication library for Next.js applications that can be extended for robotics applications.

**Biological Neural Network**: A network of interconnected neurons in biological organisms that processes information.

**Bipedal Robot**: A robot that walks on two legs, mimicking human locomotion.

**Bridge (in Gazebo/ROS)**: A component that translates messages between Gazebo and ROS 2 formats, enabling communication between the two systems.

## C

**Capstone Project**: The culminating project that integrates all concepts learned in the textbook into a complete, functional system.

**Cartesian Space**: The 3D space defined by X, Y, and Z coordinates, as opposed to joint space.

**Cognitive Architecture**: A framework for creating AI systems that simulate human cognitive processes.

**Command and Control**: The process of issuing commands to a robot and monitoring its execution.

**Computer Vision**: A field of AI focused on enabling computers to interpret and understand visual information from the world.

**Constitution (in Spec-Kit)**: A document that defines the core principles and standards that guide a project's development.

**Convolutional Neural Network (CNN)**: A type of neural network particularly effective for processing visual data.

**Coordinate Frame**: A reference system used to define positions and orientations in space.

**Curriculum Learning**: A training approach where AI models are trained on progressively more difficult tasks.

## D

**Deep Learning**: A subset of machine learning using neural networks with multiple layers to model complex patterns.

**Deep Reinforcement Learning**: A combination of deep learning and reinforcement learning for decision-making in complex environments.

**Digital Twin**: A virtual replica of a physical system that can be used for simulation, analysis, and prediction.

**Differential Drive**: A common robot configuration with two independently controlled wheels on either side of the robot.

**Docusaurus**: A static site generator designed for creating documentation websites, used for the textbook interface.

**Domain Randomization**: A technique for training AI models in simulation with randomized environments to improve real-world transfer.

**Dynamic Movement Primitive (DMP)**: A mathematical framework for representing and generating movements in robotics.

## E

**Embodied AI**: Artificial intelligence that interacts with and learns from physical environments through robotic bodies.

**Embodied Cognition**: The theory that cognitive processes are shaped by the body's interactions with the environment.

**End Effector**: The tool or device at the end of a robotic arm, such as a gripper or welding torch.

**Episode**: A complete trial in reinforcement learning from start to finish, typically ending when a goal is reached or a failure occurs.

**Epoch**: One complete pass through the entire training dataset in machine learning.

**Environment (in robotics)**: The physical or simulated world in which a robot operates and interacts.

## F

**Forward Kinematics**: The process of calculating the position of a robot's end effector based on joint angles.

**Frustrum**: The pyramid-shaped region visible to a camera, defined by its field of view.

## G

**Gazebo**: A 3D simulation environment that provides realistic physics simulation, high-quality graphics, and convenient programmatic interfaces.

**General Artificial Intelligence (GAI)**: Hypothetical AI that exhibits human-level intelligence across a wide range of tasks.

**Generative Adversarial Network (GAN)**: A type of AI model with two competing neural networks that generate realistic data.

**Gripper**: A device at the end of a robot arm designed to grasp and hold objects.

**Grounded Language Learning**: Learning language concepts through interaction with the physical world.

## H

**Hardware-in-the-Loop (HIL)**: A testing method that combines real hardware with simulated components.

**Haptic Feedback**: The use of touch sensation in human-computer interaction.

**Heuristic**: A practical approach to problem-solving that may not guarantee optimal results but is efficient.

**Humanoid Robot**: A robot with human-like form and capabilities.

**Hyperparameter**: A parameter of a learning algorithm that is set before the learning process begins.

## I

**Inverse Kinematics**: The process of calculating joint angles needed to position a robot's end effector at a desired location.

**Isaac Sim**: NVIDIA's robotics simulation environment built on the Omniverse platform with photorealistic rendering and physics simulation.

**Isaac ROS**: NVIDIA's collection of hardware-accelerated perception and navigation packages for ROS 2.

**Iteration**: A single execution of a repetitive process in machine learning or algorithm execution.

**Integration**: The process of combining different components or systems to work together as a unified whole.

## J

**Joint Space**: The space defined by a robot's joint angles, as opposed to Cartesian space.

**Jacobian Matrix**: A matrix that relates joint velocities to end-effector velocities in robotics.

## K

**Kinematics**: The study of motion without considering the forces that cause it.

**Knowledge Graph**: A structured representation of knowledge that shows relationships between entities.

## L

**Large Language Model (LLM)**: An AI model trained on vast amounts of text data to understand and generate human-like language.

**Legged Locomotion**: The act of moving using legs, as opposed to wheeled or tracked locomotion.

**LiDAR**: Light Detection and Ranging, a technology that uses laser pulses to measure distances.

**Machine Learning**: A subset of AI focused on enabling systems to learn and improve from experience without explicit programming.

**Manipulation**: The process of controlling and interacting with objects using robotic effectors.

**Model Predictive Control (MPC)**: A control method that uses a model of the system to predict future behavior and optimize control actions.

## N

**Navigation**: The process of planning and executing movement through an environment.

**Neural Network**: A computational model inspired by biological neural networks used in machine learning.

**NVIDIA Isaac**: NVIDIA's robotics platform that includes simulation, perception, and navigation tools.

**Non-Holonomic Constraint**: A constraint that limits the instantaneous motion of a system, such as a car that cannot move sideways.

## O

**Observation Space**: The set of all possible sensor inputs that an agent can receive from its environment.

**Octree**: A tree data structure in which each internal node has exactly eight children, used for 3D spatial partitioning.

**OpenAI**: An artificial intelligence research laboratory that develops and provides access to advanced AI models.

**Operational Space**: The space in which a robot's end effector operates, typically Cartesian space.

## P

**Perception**: The process of interpreting sensory information to understand the environment.

**Physical AI**: AI systems that interact with and operate in the physical world.

**Point Cloud**: A collection of data points in 3D space, typically generated by 3D scanners or LiDAR.

**Pose**: The position and orientation of an object in space.

**Psychomotor Learning**: The development of motor skills through practice and physical feedback.

## R

**RAG (Retrieval-Augmented Generation)**: A technique that combines information retrieval with language generation to improve accuracy and relevance.

**Reinforcement Learning**: A type of machine learning where agents learn to make decisions by interacting with an environment and receiving rewards.

**Robot Operating System (ROS)**: A flexible framework for writing robot software that provides services like hardware abstraction, device drivers, and message passing.

**ROS 2**: The second generation of the Robot Operating System with improved security, real-time support, and multi-robot capabilities.

**ROS 2 Humble Hawksbill**: The codename for the ROS 2 distribution released in May 2022 and supported until May 2027.

**ROS Bridge**: A component that enables communication between ROS and other systems like Gazebo or Unity.

**Rigid Body**: An object that maintains its shape and size regardless of external forces.

## S

**Sensor Fusion**: The process of combining data from multiple sensors to improve perception accuracy.

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Spec-Driven Development**: A development methodology where specifications are written first and guide implementation.

**State Space**: The set of all possible states that a system can be in.

**Static Stability**: Stability achieved when a robot's center of mass remains within its support polygon.

**Synthetic Data**: Artificially generated data that mimics real-world observations.

## T

**Task Space**: The space in which a robot's tasks are defined, typically related to end-effector positions and orientations.

**TF (Transforms)**: A package in ROS that keeps track of coordinate frame relationships over time.

**TF Tree**: A hierarchical representation of all coordinate frame relationships in a ROS system.

**Thigmotaxis**: The tendency of some animals to follow walls or stay near surfaces, relevant for robot navigation.

**Timestep**: The discrete time interval used in simulation and control systems.

**Trajectory**: A time-parameterized path that includes both position and timing information.

## V

**VLA (Vision-Language-Action)**: A paradigm that integrates visual perception, language understanding, and physical action in embodied AI systems.

**VSLAM (Visual SLAM)**: SLAM that uses visual sensors (cameras) as the primary input.

**Virtual Reality (VR)**: A computer-generated simulation of a physical environment.

**Vision-Language Model**: An AI model that jointly processes visual and textual information.

## W

**Waypoint**: A predetermined point along a route used for navigation.

**Whole-Body Control**: Control strategies that consider the entire robot's dynamics and constraints simultaneously.

**Workspace**: The space in which a robot's end effector can operate.

## X

**Xacro**: An XML macro language that simplifies complex URDF files by allowing variables, constants, and macros.

## Y

**Yaw**: Rotation around the vertical (Z) axis.

## Z

**Zero-Shot Learning**: The ability of a model to recognize objects or perform tasks it hasn't been explicitly trained on.

**ZMP (Zero Moment Point)**: A concept in robotics used to assess the stability of legged robots during locomotion.

---

This glossary provides definitions for the technical terminology used throughout the Physical AI & Humanoid Robotics textbook. As new terms are introduced in updates to the textbook, this glossary will be expanded accordingly.